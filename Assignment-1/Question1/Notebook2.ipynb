{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1dccaa",
   "metadata": {},
   "source": [
    "# Question (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec4d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens with cleaning of files,remove punctuations\n",
    "\n",
    "punctuations=[\"।\",\";\",\",\",\":\",\"!\",'\"',\"?\",\":-\",\"-\",\"{\",\"(\",\"}\",\")\",\"_\",\"०\",\"S\",\"―\",\"=\",\"[\",\"]\",\"......\",\":-\",\".\",\"॥\",'”',\"|\"]\n",
    "tokens=[]\n",
    "f= open('corpus.txt3',encoding= 'utf-8') \n",
    "for line in f:\n",
    "        new_line = \"\"\n",
    "        for i in line:\n",
    "            if i not in punctuations:\n",
    "                new_line += i\n",
    "        line = new_line\n",
    "        tokens+=line.split()\n",
    "tokens        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b02c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenf.txt','w',encoding='utf8')as f:\n",
    "    for line in  tokens:\n",
    "            f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# white-space tokens with their frequencies\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(tokens)\n",
    "freq_lst = [(k, v) for k, v in c.items()]\n",
    "freq_lst = sorted(freq_lst, key=lambda item: item[1],reverse=True)\n",
    "print (freq_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b918450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correction of words\n",
    "\n",
    "list1=[\"ा\", \"ि\", \"ी\", \"ु\", \"ू\", \"े\", \"ो\", \"ै\", \"ौ\", \"ृ\", \"ॄ\", \"ॉ\", \"ं\"]\n",
    "dict={\"ा\":\"आ\",\"ि\":\"इ\",\"ी\":\"ई\",\"ु\":\"उ\",\"ू\":\"ऊ\",\"े\":\"ए\",\"ै\":\"ऐ\",\"ो\":\"ओ\",\"ौ\":\"औ\", \"ं\":\"अं\",\"ृ\":\"ऋ\",'ॉ':\"ऑ\",\"ॄ\":\"ॠ\"}\n",
    "vowels = [\"ा\", \"ि\", \"ी\", \"ु\", \"ू\", \"े\", \"ो\", \"ै\", \"ौ\", \"ृ\", \"ॄ\", \"ॉ\", \"ं\", \"्\",\"अ\", \"आ\", \"इ\", \"ई\", \"उ\", \"ऊ\", \"ऋ\",\"ए\", \"ऐ\", \"ओ\", \"औ\", \"अं\", \"अः\"]\n",
    "def correction(word):\n",
    "    temp = \"\"\n",
    "    split_words = []\n",
    "    for i in range(len(word)):\n",
    "        temp += word[i]\n",
    "        if word[i]=='्' and i!=0: \n",
    "            temp=word[i-1]+chr(2381)\n",
    "            if len(split_words):\n",
    "                split_words.pop()\n",
    "            #split_words.append(temp)\n",
    "            temp = \"\"\n",
    "        if word[i] not in vowels and i!=0  and not word[i].isdigit() : \n",
    "            temp=word[i]+chr(2381)\n",
    "           # split_words.pop()\n",
    "            split_words.append(temp)\n",
    "            split_words.append('अ')\n",
    "            temp = \"\"\n",
    "        if word[i] not in vowels and i==0  and not word[i].isdigit() : \n",
    "            temp=word[i]+chr(2381)\n",
    "            split_words.append(temp)\n",
    "            split_words.append('अ')\n",
    "            temp = \"\"  \n",
    "        if word[i]  in list1 and i!=0: \n",
    "            temp=word[i-1]+chr(2381)\n",
    "            if len(split_words):\n",
    "                split_words.pop()\n",
    "            split_words.append(dict[word[i]])\n",
    "            temp = \"\"  \n",
    "        if temp != \"\":\n",
    "            split_words.append(temp)\n",
    "            temp=\"\"\n",
    "   \n",
    "    return split_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#syllables for words\n",
    "\n",
    "vowels = [\"ा\", \"ि\", \"ी\", \"ु\", \"ू\", \"े\", \"ो\", \"ै\", \"ौ\", \"ृ\", \"ॄ\", \"ॉ\", \"ं\",'्',\"अ\", \"आ\", \"इ\", \"ई\", \"उ\", \"ऊ\", \"ऋ\",\"ए\", \"ऐ\", \"ओ\", \"औ\", \"अं\", \"अः\"]\n",
    "def syllable(word):\n",
    "    split_syllable=[]\n",
    "    temp=\"\"\n",
    "    l=len(word)\n",
    "    for i in range(len(word)-1):\n",
    "        temp+=word[i]\n",
    "        if word[i] in vowels and word[i]!='्' and not word[i].isdigit():\n",
    "            split_syllable.append(temp)\n",
    "            temp=\"\"\n",
    "            continue\n",
    "        if word[i] not in vowels and word[i+1] not in vowels and not word[i].isdigit(): \n",
    "            split_syllable.append(temp)\n",
    "            temp=\"\"\n",
    "            continue\n",
    "        if word[i]== '्' :\n",
    "            temp = temp[:-2]\n",
    "            temp+=word[i-1]+chr(2381)\n",
    "            continue\n",
    "    if temp!=\"\":\n",
    "        split_syllable.append(temp)\n",
    "    if l!=1:    \n",
    "        if word[l-1] in vowels and not word[l-1].isdigit():\n",
    "            x=split_syllable.pop()\n",
    "            split_syllable.append(x+word[l-1])\n",
    "        if word[l-1] not in  vowels and word[i-2]=='्' and not word[l-1].isdigit():\n",
    "            y=split_syllable.pop()\n",
    "            split_syllable.append(y+word[l-1])\n",
    "        if word[l-1] not in  vowels and word[i-2]!='्' and not word[l-1].isdigit():\n",
    "                split_syllable.append(word[l-1])    \n",
    "        if word[l-1].isdigit():\n",
    "            z=split_syllable.pop()\n",
    "            split_syllable.append(z+word[l-1])\n",
    "    else:\n",
    "        split_syllable.append(word)\n",
    "    \n",
    "   \n",
    "    return split_syllable \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_tokens={}\n",
    "bigrams_syllables={}\n",
    "bigrams_char={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66979dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(doc, n):\n",
    "        sequence=[doc[i:] for i in range(n)]\n",
    "        return (zip(*sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a25959",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations=[\"।\",\";\",\",\",\":\",\"!\",'\"',\"?\",\":-\",\"-\",\"{\",\"(\",\"}\",\")\",\"_\",\"०\",\"S\",\"―\",\"=\",\"[\",\"]\",\"......\",\":-\",\".\",\"॥\",'”',\"|\"]\n",
    "corrected_dict={}\n",
    "syllable_dict={}\n",
    "token_chr_syll={}\n",
    "\n",
    "filename=open(\"output.txt\",\"r\",encoding='utf8')\n",
    "\n",
    "token = []\n",
    "j=0\n",
    "for line in filename:\n",
    "    new_line = \"\"\n",
    "    for i in line:\n",
    "        if i not in punctuations:\n",
    "            new_line += i\n",
    "        line = new_line\n",
    "    token=line.split()\n",
    "    for word in token:\n",
    "        if word not in corrected_dict:\n",
    "            new_word = correction(word)\n",
    "            corrected_dict[word] = new_word\n",
    "        else:\n",
    "            new_word = corrected_dict[word]\n",
    "        if word not in syllable_dict:\n",
    "            split_words = syllable(word)\n",
    "            syllable_dict[word] = split_words\n",
    "        else:\n",
    "            split_words = syllable_dict[word]                \n",
    "   \n",
    "        token_chr_syll[word]=((corrected_dict[word],len(corrected_dict[word]),(syllable_dict[word],len(syllable_dict[word]))))\n",
    "    for i in find_ngrams(new_word, 2):\n",
    "                    if i not in bigrams_char:\n",
    "                        bigrams_char[i]=1\n",
    "                    else:\n",
    "                        bigrams_char[i]+=1\n",
    "    for i in find_ngrams(split_words, 2):\n",
    "                    if i in bigrams_syllables:\n",
    "                        bigrams_syllables[i]+=1\n",
    "                    else:\n",
    "                        bigrams_syllables[i]=1 \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380de3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#charcters  list with their frequency\n",
    "#syllables list with their frequency\n",
    "\n",
    "characters=[]\n",
    "syllables=[]\n",
    "for word in tokens:\n",
    "    x_word=correction(word)\n",
    "    for i in range(len(x_word)): \n",
    "        characters.append(x_word[i])\n",
    "            \n",
    "    y_word=syllable(word)   \n",
    "    for i in range(len(y_word)): \n",
    "        syllables.append(y_word[i])\n",
    "\n",
    "c=collections.Counter(characters)\n",
    "characters_freq=[(k,v) for k,v in c.items()]\n",
    "characters_freq = sorted(characters_freq, key=lambda item: item[1],reverse=True)\n",
    "print(characters_freq)\n",
    "\n",
    "\n",
    "c=collections.Counter(syllables)\n",
    "syllables_freq=[(k,v) for k,v in c.items()]\n",
    "syllables_freq = sorted(syllables_freq, key=lambda item: item[1],reverse=True)\n",
    "print(syllables_freq)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd5b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('characters.txt','w',encoding='utf8')as f:\n",
    "    for line in  characters_freq:\n",
    "            f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f92c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('syallbles.txt','w',encoding='utf8')as f:\n",
    "    for line in  syllables_freq:\n",
    "            f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2088fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"token_chr_syll.txt\",'w',encoding='utf-8') as f:\n",
    "      print(token_chr_syll,file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bigrams_char.txt','w',encoding='utf8')as f:\n",
    "    for line in bigrams_char:\n",
    "            f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42cb14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bigrams_syllables.txt','w',encoding='utf8')as f:\n",
    "    for line in bigrams_syllables:\n",
    "            f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ff89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_char.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_syllables.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47946543",
   "metadata": {},
   "source": [
    "# Question (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here first separate each character with space and then find freq of each word such that we can easily find pair frequency\n",
    "word_freq={}\n",
    "for word in tokens:\n",
    "            words=' '.join(word)+ ' '\n",
    "            if words not in word_freq:\n",
    "                word_freq[words]=1\n",
    "            else:\n",
    "                word_freq[words]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding pairs with their frequency\n",
    "\n",
    "def get_pair_freq(word_freq):\n",
    "    pair=collections.defaultdict(int)\n",
    "    for word,freq in word_freq.items():\n",
    "        char=word.split()        \n",
    "        for i in range(len(char)-1):\n",
    "            pair[char[i],char[i+1]] +=freq   \n",
    "    return pair\n",
    "\n",
    "def get_tokens(word_freq):\n",
    "    tokens=collections.defaultdict(int)\n",
    "    for word,freq in word_freq.items():\n",
    "        char=word.split()\n",
    "        for token in char:\n",
    "            tokens[token] +=freq\n",
    "    return tokens\n",
    "\n",
    "def merge_pair(pair,word_freq):\n",
    "    word_new_freq={}\n",
    "    pattern = re.escape(' '.join(pair))\n",
    "    for word in word_freq:\n",
    "        new_word = re.sub(pattern,''.join(pair) , word)\n",
    "        word_new_freq[new_word] = word_freq[word]\n",
    "\n",
    "    return word_new_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9fee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,collections\n",
    "vocab = 1000\n",
    "\n",
    "new_tokens = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(vocab):\n",
    "    pairs = get_pair_freq(word_freq)\n",
    "    if not pairs:\n",
    "        break\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    new_tokens.append(''.join(best))\n",
    "    word_freq = merge_pair(best, word_freq)\n",
    "    #print(word_freq)\n",
    "    token = get_tokens(word_freq)\n",
    "    print('Iter:',i)\n",
    "    print('Best pair:',best)\n",
    "    #print('Number of tokens:',len(token))\n",
    "    #print('Tokens:',token)\n",
    "    print('==========')\n",
    "print(new_tokens)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# white-space  BPE tokens with their frequencies\n",
    "import collections\n",
    "c = collections.Counter(new_tokens)\n",
    "new_tokens_freq = [(k, v) for k, v in c.items()]\n",
    "new_tokens_freq = sorted(new_tokens_freq, key=lambda item: item[1],reverse=True)\n",
    "print (new_tokens_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_tokens={}\n",
    "bigrams_syllables={}\n",
    "bigrams_char={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigram_characters\n",
    "#bigram-syllables\n",
    "\n",
    "\n",
    "corrected_dict_new={}\n",
    "syllable_dict_new={}\n",
    "token_chr_syll_new={}\n",
    "\n",
    "for word in new_tokens:\n",
    "    if word not in corrected_dict_new:\n",
    "        new_word = correction(word)\n",
    "        corrected_dict_new[word] = new_word\n",
    "    else:\n",
    "        new_word = corrected_dict_new[word]\n",
    "    if word not in syllable_dict_new:\n",
    "        split_words = syllable(word)\n",
    "        syllable_dict_new[word] = split_words\n",
    "    else:\n",
    "        split_words = syllable_dict_new[word]                \n",
    "   \n",
    "    token_chr_syll_new[word]=((corrected_dict_new[word],len(corrected_dict_new[word]),(syllable_dict_new[word],len(syllable_dict_new[word]))))\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    for i in find_ngrams(new_word, 2):              #bigram characters\n",
    "                    if i not in bigrams_char:\n",
    "                        bigrams_char[i]=1\n",
    "                    else:\n",
    "                        bigrams_char[i]+=1\n",
    "    for i in find_ngrams(split_words, 2):            #bigram syllables\n",
    "                    if i in bigrams_syllables:\n",
    "                        bigrams_syllables[i]+=1\n",
    "                    else:\n",
    "                        bigrams_syllables[i]=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b0983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPE characters  list with their frequency and BPE syllables list with their frequency\n",
    "characters_new=[]\n",
    "syllables_new=[]\n",
    "for word in new_tokens:\n",
    "    x_word=correction(word)\n",
    "    for i in range(len(x_word)): \n",
    "        characters_new.append(x_word[i])\n",
    "            \n",
    "    y_word=syllable(word)   \n",
    "    for i in range(len(y_word)): \n",
    "        syllables_new.append(y_word[i])\n",
    "\n",
    "c=collections.Counter(characters_new)\n",
    "characters_freq_new=[(k,v) for k,v in c.items()]\n",
    "characters_freq_new = sorted(characters_freq_new, key=lambda item: item[1],reverse=True)\n",
    "print(characters_freq_new)\n",
    "\n",
    "\n",
    "c=collections.Counter(syllables_new)\n",
    "syllables_freq_new=[(k,v) for k,v in c.items()]\n",
    "syllables_freq_new = sorted(syllables_freq_new, key=lambda item: item[1],reverse=True)\n",
    "print(syllables_freq_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e79c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bigrams_char)\n",
    "bigrams_char.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bigrams_syllables)\n",
    "bigrams_syllables.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams_BPE_tokens\n",
    "for i in find_ngrams(new_tokens, 2):\n",
    "                    if i in bigrams_tokens:\n",
    "                        bigrams_tokens[i]+=1\n",
    "                    else:\n",
    "                        bigrams_tokens[i]=1\n",
    "print(bigrams_tokens)\n",
    "bigrams_tokens.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919734a",
   "metadata": {},
   "source": [
    "# Question (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec827da",
   "metadata": {},
   "outputs": [],
   "source": [
    "True_positives=[]\n",
    "for word in new_tokens:\n",
    "    if word in tokens:\n",
    "        True_positives.append(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49102a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for vocab size 1k\n",
    "Precision=len(True_positives)/len(new_tokens)                  #precision=TruePositives/(FalsePositives+TruePositives)\n",
    "Recall=len(True_positives)/len(freq_lst)                       #Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "F_score=2*(Precision*Recall)/(Precision+Recall)                #Harmonic mean of precision and recall\n",
    "print(\"Precision=\",Precision)\n",
    "print(\"Recall=\",Recall)\n",
    "print(\"F_score=\",F_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b36e25",
   "metadata": {},
   "source": [
    "# Question (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1574908",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma={}\n",
    "import pyconll\n",
    "data_file = 'hi_hdtb-ud-train.conllu'\n",
    "conll = pyconll.iter_from_file(data_file)\n",
    "\n",
    "for sentence in conll:\n",
    "    for word in sentence:\n",
    "        lemma[word.form]=word.lemma\n",
    "            \n",
    "lemm_freq={}\n",
    "for word in lemma.values():\n",
    "   # print(word)\n",
    "    if word in lemm_freq:\n",
    "        lemm_freq[word]+=1 \n",
    "    else:\n",
    "        lemm_freq[word]=1\n",
    "lemm_freq.items()\n",
    "lemm_freq = sorted(lemm_freq.items(), key=lambda item: item[1],reverse=True)\n",
    "lemm_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lemma_freq.txt','w',encoding='utf8')as f:\n",
    "    for line in lemm_freq:\n",
    "            f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d40a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('surfacelemma.txt','w',encoding='utf8')as f:\n",
    "    for line in  lemma:\n",
    "            f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d81c40",
   "metadata": {},
   "source": [
    "# Question (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93430fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[] \n",
    "for i in range (1000):\n",
    "    x.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency of tokens\n",
    "y=[]\n",
    "for i in range(1000):\n",
    "    y.append(freq_lst[i][1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for token_frequency vs rank\n",
    "plt.xlabel(\"rank\")\n",
    "plt.ylabel(\"token_frequency\")\n",
    "plt.title(\" Zipfian up to first 1000 frequency\")\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[] \n",
    "for i in range (1000):\n",
    "    x.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f8f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency of BPE_token\n",
    "y=[]\n",
    "for i in range(1000):\n",
    "    y.append(new_tokens_freq[i][1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd36457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for BPE_token_frequency vs rank\n",
    "plt.xlabel(\"rank\")\n",
    "plt.ylabel(\"new_token1k_frequency\")\n",
    "plt.plot(x,y)\n",
    "\n",
    "\n",
    "#NOT follow zifian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e047220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[] \n",
    "for i in range (2000):\n",
    "    x.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0affce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#syllables frequency\n",
    "y=[]\n",
    "for i in range(2000):\n",
    "    y.append(syllables_freq[i][1])  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47208a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"rank\")\n",
    "plt.ylabel(\"syllables_frequency\")\n",
    "plt.plot(x,y)\n",
    "\n",
    "#follow zifian upto to the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae15d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[] \n",
    "for i in range (1000):\n",
    "    x.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#characeters frequency\n",
    "y=[]\n",
    "for i in range(1000):\n",
    "    y.append(characters_freq[i][1])  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd8ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"rank\")\n",
    "plt.ylabel(\"characters_frequency\")\n",
    "plt.plot(x,y)\n",
    "\n",
    "#follow zifian up to the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=[] \n",
    "for i in range (1000):\n",
    "    x.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec33a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#characeters frequency\n",
    "y=[]\n",
    "for i in range(1000):\n",
    "    y.append(lemm_freq[i][1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aecb51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"rank\")\n",
    "plt.ylabel(\"lemma_frequency\")\n",
    "plt.title(\" Zipfian up to first 1000 frequency\")\n",
    "plt.plot(x,y)\n",
    "\n",
    "\n",
    "#follow zifian upto the range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cabd7e",
   "metadata": {},
   "source": [
    "# Question (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28023a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suffix found from the stripping of surface form \n",
    "\n",
    "suffix=[]\n",
    "for word,lem in lemma.items():\n",
    "    f=0\n",
    "    if(len(word)<len(lem)):\n",
    "        continue\n",
    "    if(len(word)==len(lem)):\n",
    "        continue\n",
    "    else:\n",
    "            for i in range(len(lem)):\n",
    "\n",
    "                f=f+1\n",
    "                if word[i]==lem[i]:\n",
    "                    continue\n",
    "            temp=\"\"\n",
    "            for i in range(f,len(word)):\n",
    "                temp=temp+word[i]\n",
    "            suffix.append(temp)\n",
    "           \n",
    "suffix            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suffix with their frequency\n",
    "\n",
    "import collections\n",
    "c = collections.Counter(suffix)\n",
    "suffix = [(k, v) for k, v in c.items()]\n",
    "suffix = sorted(suffix, key=lambda item: item[1],reverse=True)\n",
    "print(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92501c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    print(suffix[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c5850",
   "metadata": {},
   "source": [
    "# Question 7(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04431ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ई नी या ता   are the suffixes with my knowledge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
